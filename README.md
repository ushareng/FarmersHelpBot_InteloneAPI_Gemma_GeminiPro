# Farmers helper bot using Intel One API and Gemma-2B and Gemini Pro

Making large language models (LLMs) open source greatly enhances the accessibility of AI technology worldwide. While it’s improbable, it’s not impossible that the next AI breakthrough could originate from someone lacking access to extensively distributed accelerator clusters. Yet, the scenario shifts notably in AI application development, where there’s greater flexibility in choosing product development infrastructure. This convergence of CPU availability, scalability, and the genuine open-source licensing of LLMs emerges as a significant facilitator for AI advancement.

This project delves into the captivating endeavor of fine-tuning Gemma, recently unveiled by Google, on Intel Xeon processors utilizing the Hugging Face Supervised Fine-tuning Trainer (SFTTrainer), Intel Extension for PyTorch (IPEX) coupled with Intel Advanced Matrix Extensions (Intel® AMX), and Auto Mixed Precision (AMP) featuring Bfloat16.
